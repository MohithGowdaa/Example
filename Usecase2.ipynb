{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949b9b3c",
   "metadata": {},
   "source": [
    "#  Use case 2:Predicting wether Immediate clean up required or not based on Trash level,Trash weight and no.of visitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397d50c",
   "metadata": {},
   "source": [
    "# Model 1:Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5def92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Regularized): 1.00\n",
      "Confusion Matrix (Regularized):\n",
      " [[3783    0]\n",
      " [   0 3798]]\n",
      "Classification Report (Regularized):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3783\n",
      "           1       1.00      1.00      1.00      3798\n",
      "\n",
      "    accuracy                           1.00      7581\n",
      "   macro avg       1.00      1.00      1.00      7581\n",
      "weighted avg       1.00      1.00      1.00      7581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the preprocessed data\n",
    "ocean = pd.read_csv('cleaned_ocean.csv')\n",
    "\n",
    "# Selecting relevant columns\n",
    "X = ocean[['Pounds', 'Total Items Collected', 'People']]\n",
    "y = ocean['Immediate Cleanup Required']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree model\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=5,              # Example: maximum depth of the tree\n",
    "    min_samples_split=10,     # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=4,       # Minimum number of samples required to be at a leaf node\n",
    "    random_state=42)\n",
    "# Train the model\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_regularized = accuracy_score(y_test, y_pred)\n",
    "conf_matrix_regularized = confusion_matrix(y_test, y_pred)\n",
    "classification_rep_regularized = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy (Regularized): {accuracy_regularized:.2f}\")\n",
    "print(\"Confusion Matrix (Regularized):\\n\", conf_matrix_regularized)\n",
    "print(\"Classification Report (Regularized):\\n\", classification_rep_regularized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83309026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediate cleanup required\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the preprocessed data\n",
    "ocean = pd.read_csv('cleaned_ocean.csv')\n",
    "\n",
    "# Selecting relevant columns\n",
    "X = ocean[['Pounds', 'Total Items Collected', 'People']]\n",
    "y = ocean['Immediate Cleanup Required']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "def predict_cleanup_requirement(pounds, total_items_collected, people):\n",
    "    # Convert the inputs into a DataFrame\n",
    "    input_data = pd.DataFrame({'Pounds': [pounds], \n",
    "                               'Total Items Collected': [total_items_collected], \n",
    "                               'People': [people]})\n",
    "    \n",
    "    # Standardize the features\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = dt_model.predict(input_data_scaled)\n",
    "\n",
    "    # Translate the prediction to a more readable format\n",
    "    if prediction == 0:\n",
    "        return \"No immediate cleanup required\"\n",
    "    else:\n",
    "        return \"Immediate cleanup required\"\n",
    "\n",
    "# Example usage of the function\n",
    "example_pounds = 100\n",
    "example_total_items = 50\n",
    "example_people = 10\n",
    "\n",
    "prediction = predict_cleanup_requirement(example_pounds, example_total_items, example_people)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478feb45",
   "metadata": {},
   "source": [
    "# Model 2:Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0d7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix of binary class classification problem:\n",
      " [[3783    0]\n",
      " [   0 3798]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score,recall_score,f1_score\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "training_accuracy = accuracy_score(y_train, dt_model.predict(X_train_scaled))\n",
    "validation_accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Training Accuracy: {training_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {validation_accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Confusion Matrix of binary class classification problem:\\n\",conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a012c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediate cleanup required\n"
     ]
    }
   ],
   "source": [
    "def predict_cleanup_requirement(pounds, total_items_collected, people, model, scaler):\n",
    "    # Convert the inputs into a DataFrame\n",
    "    input_data = pd.DataFrame({'Pounds': [pounds], \n",
    "                               'Total Items Collected': [total_items_collected], \n",
    "                               'People': [people]})\n",
    "    \n",
    "    # Standardize the features\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction_label = model.predict(input_data_scaled)[0]\n",
    "\n",
    "    # Translate the prediction to a more readable format\n",
    "    cleanup_classes = [\"No immediate cleanup required\", \"Immediate cleanup required\"]\n",
    "    prediction_readable = cleanup_classes[prediction_label]\n",
    "\n",
    "    return prediction_readable\n",
    "\n",
    "# Example usage of the function\n",
    "example_pounds = 100\n",
    "example_total_items = 50\n",
    "example_people = 10\n",
    "\n",
    "prediction = predict_cleanup_requirement(example_pounds, example_total_items, example_people, dt_model, scaler)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e24e1",
   "metadata": {},
   "source": [
    "## Model 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc33c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Logistic Regression): 0.86\n",
      "Test Accuracy (Logistic Regression): 0.87\n",
      "Precision (Logistic Regression): 0.88\n",
      "Recall (Logistic Regression): 0.87\n",
      "F1 Score (Logistic Regression): 0.87\n",
      "Confusion Matrix of binary class classification problem (Logistic Regression):\n",
      " [[3620  163]\n",
      " [ 841 2957]]\n",
      "Classification Report (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      3783\n",
      "           1       0.95      0.78      0.85      3798\n",
      "\n",
      "    accuracy                           0.87      7581\n",
      "   macro avg       0.88      0.87      0.87      7581\n",
      "weighted avg       0.88      0.87      0.87      7581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
    "training_accuracy_lr = accuracy_score(y_train, lr_model.predict(X_train_scaled))\n",
    "validation_accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f\"Training Accuracy (Logistic Regression): {training_accuracy_lr:.2f}\")\n",
    "print(f\"Test Accuracy (Logistic Regression): {validation_accuracy_lr:.2f}\")\n",
    "print(f\"Precision (Logistic Regression): {precision_lr:.2f}\")\n",
    "print(f\"Recall (Logistic Regression): {recall_lr:.2f}\")\n",
    "print(f\"F1 Score (Logistic Regression): {f1_lr:.2f}\")\n",
    "print(f\"Confusion Matrix of binary class classification problem (Logistic Regression):\\n\", conf_matrix_lr)\n",
    "print(\"Classification Report (Logistic Regression):\\n\", classification_rep_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04469f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No immediate cleanup required\n"
     ]
    }
   ],
   "source": [
    "def predict_cleanup_requirement(pounds, total_items_collected, people, model, scaler):\n",
    "    # Convert the inputs into a DataFrame\n",
    "    input_data = pd.DataFrame({'Pounds': [pounds], \n",
    "                               'Total Items Collected': [total_items_collected], \n",
    "                               'People': [people]})\n",
    "    \n",
    "    # Standardize the features\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction_label = model.predict(input_data_scaled)[0]\n",
    "\n",
    "    # Translate the prediction to a more readable format\n",
    "    cleanup_classes = [\"No immediate cleanup required\", \"Immediate cleanup required\"]\n",
    "    prediction_readable = cleanup_classes[prediction_label]\n",
    "\n",
    "    return prediction_readable\n",
    "\n",
    "# Example usage of the function\n",
    "example_pounds = 100\n",
    "example_total_items = 50\n",
    "example_people = 10\n",
    "\n",
    "prediction = predict_cleanup_requirement(example_pounds, example_total_items, example_people, lr_model, scaler)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a15a4",
   "metadata": {},
   "source": [
    "## Model 4: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2a17da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\desha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (KNN): 0.99\n",
      "Test Accuracy (KNN): 0.98\n",
      "Precision (KNN): 0.98\n",
      "Recall (KNN): 0.98\n",
      "F1 Score (KNN): 0.98\n",
      "Confusion Matrix of binary class classification problem (KNN):\n",
      " [[3731   52]\n",
      " [  69 3729]]\n",
      "Classification Report (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3783\n",
      "           1       0.99      0.98      0.98      3798\n",
      "\n",
      "    accuracy                           0.98      7581\n",
      "   macro avg       0.98      0.98      0.98      7581\n",
      "weighted avg       0.98      0.98      0.98      7581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Initialize the K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "training_accuracy_knn = accuracy_score(y_train, knn_model.predict(X_train_scaled))\n",
    "validation_accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted')\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "\n",
    "print(f\"Training Accuracy (KNN): {training_accuracy_knn:.2f}\")\n",
    "print(f\"Test Accuracy (KNN): {validation_accuracy_knn:.2f}\")\n",
    "print(f\"Precision (KNN): {precision_knn:.2f}\")\n",
    "print(f\"Recall (KNN): {recall_knn:.2f}\")\n",
    "print(f\"F1 Score (KNN): {f1_knn:.2f}\")\n",
    "print(f\"Confusion Matrix of binary class classification problem (KNN):\\n\", conf_matrix_knn)\n",
    "print(\"Classification Report (Logistic Regression):\\n\", classification_rep_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4187c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediate cleanup required\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "def predict_cleanup_requirement_knn(pounds, total_items_collected, people, model, scaler):\n",
    "    # Convert the inputs into a DataFrame\n",
    "    input_data = pd.DataFrame({'Pounds': [pounds], \n",
    "                               'Total Items Collected': [total_items_collected], \n",
    "                               'People': [people]})\n",
    "    \n",
    "    # Standardize the features\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction_label = model.predict(input_data_scaled)[0]\n",
    "\n",
    "    # Translate the prediction to a more readable format\n",
    "    cleanup_classes = [\"No immediate cleanup required\", \"Immediate cleanup required\"]\n",
    "    prediction_readable = cleanup_classes[prediction_label]\n",
    "\n",
    "    return prediction_readable\n",
    "\n",
    "# Example usage of the function with KNN model\n",
    "example_pounds_knn = 100\n",
    "example_total_items_knn = 50\n",
    "example_people_knn = 10\n",
    "\n",
    "prediction_knn = predict_cleanup_requirement_knn(example_pounds_knn, example_total_items_knn, example_people_knn, knn_model, scaler)\n",
    "print(prediction_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02eee7e",
   "metadata": {},
   "source": [
    "# Model 5 :SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0deb4a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SVM): 0.88\n",
      "Confusion Matrix (SVM):\n",
      " [[3570  213]\n",
      " [ 692 3106]]\n",
      "Classification Report (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      3783\n",
      "           1       0.94      0.82      0.87      3798\n",
      "\n",
      "    accuracy                           0.88      7581\n",
      "   macro avg       0.89      0.88      0.88      7581\n",
      "weighted avg       0.89      0.88      0.88      7581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the preprocessed data\n",
    "ocean = pd.read_csv('cleaned_ocean.csv')\n",
    "\n",
    "# Selecting relevant columns\n",
    "X = ocean[['Pounds', 'Total Items Collected', 'People']]\n",
    "y = ocean['Immediate Cleanup Required']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy (SVM): {accuracy_svm:.2f}\")\n",
    "print(\"Confusion Matrix (SVM):\\n\", conf_matrix_svm)\n",
    "print(\"Classification Report (SVM):\\n\", classification_rep_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c58cf099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No immediate cleanup required\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_cleanup_requirement_svm(pounds, total_items_collected, people):\n",
    "    # Convert the inputs into a DataFrame\n",
    "    input_data = pd.DataFrame({'Pounds': [pounds], \n",
    "                               'Total Items Collected': [total_items_collected], \n",
    "                               'People': [people]})\n",
    "    \n",
    "    # Standardize the features\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make a prediction with the SVM model\n",
    "    prediction = svm_model.predict(input_data_scaled)\n",
    "\n",
    "    # Translate the prediction to a more readable format\n",
    "    if prediction == 0:\n",
    "        return \"No immediate cleanup required\"\n",
    "    else:\n",
    "        return \"Immediate cleanup required\"\n",
    "\n",
    "# Example of using the function\n",
    "# Example of using the function\n",
    "example_pounds = 3# Example value for pounds\n",
    "example_total_items = 57  # Example value for total items collected\n",
    "example_people = 2  # Example value for people\n",
    "\n",
    "# Using the updated function\n",
    "prediction_svm = predict_cleanup_requirement_svm(example_pounds, example_total_items, example_people)\n",
    "print(prediction_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a94dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
